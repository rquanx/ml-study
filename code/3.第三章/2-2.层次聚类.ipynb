{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means 问题：需要手动指定 K 值，需要多次测试找到最优 K 值\n",
    "# 自底向上层次聚类法：Agglomerative Clustering\n",
    "\n",
    "\n",
    "# 对于数据集 D，D = (x1,x2,.....xn) ：\n",
    "# 1.将数据集中每个样本标记为 1 类，即 D 初始时包含的类别（Class）为 C = (c1,c2....cn) 。\n",
    "# 2.计算并找出 C 中距离最近的 2 个类别，合并为 1 类。\n",
    "# 3.依次合并直到最后仅剩下一个列表，即建立起一颗完整的层次树。\n",
    "\n",
    "# 距离计算\n",
    "# 单连接：根据两种类别之间最近的元素间距离作为两类别之间的距离\n",
    "# 全连接：根据两种类别之间最远的元素间距离作为两类别之间的距离\n",
    "# 平均连接：依次计算两种类别之间两两元素间距离，并最终求得平均值作为两类别之间的距离。\n",
    "# 中心连接：平均连接虽然看起来更加合理，但是两两元素间的距离计算量往往非常庞大。有时候，也可以使用中心连接计算方法。即先计算类别中心，再以中心连线作为两类别之间的距离\n",
    "# 「单连接」和「全连接」都相对极端，容易受到噪声点和分布不均匀数据造成的干扰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# 生成 10 个二维的数据，有两个中心点，data 同时包含点数据和分类数据\n",
    "data = datasets.make_blobs(10, n_features=2, centers=2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19583348b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(data[0][:, 0], data[0][:, 1], c=data[1], s=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    a -- 数组 a\n",
    "    b -- 数组 b\n",
    "\n",
    "    返回:\n",
    "    dist -- a, b 间欧式距离\n",
    "    \"\"\"\n",
    "    # 欧式距离\n",
    "    x = float(a[0]) - float(b[0])\n",
    "    x = x * x\n",
    "    y = float(a[1]) - float(b[1])\n",
    "    y = y * y\n",
    "    dist = round(np.sqrt(x + y), 2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自底向上层次聚类\n",
    "def agglomerative_clustering(data):\n",
    "    # Agglomerative 聚类计算过程\n",
    "\n",
    "    while len(data) > 1:\n",
    "        print(\"☞ 第 {} 次迭代\\n\".format(10 - len(data) + 1))\n",
    "        min_distance = float(\"inf\")  # 设定初始距离为无穷大\n",
    "        \n",
    "        # 找到最近的两个点,并以他们的中心作为此类与其他类的距离,中心连接\n",
    "        for i in range(len(data)):\n",
    "            print(\"---\")\n",
    "            for j in range(i + 1, len(data)):\n",
    "                distance = euclidean_distance(data[i], data[j])\n",
    "                print(\"计算 {} 与 {} 距离为 {}\".format(data[i], data[j], distance))\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    min_ij = (i, j)\n",
    "        i, j = min_ij  # 最近数据点序号\n",
    "        data1 = data[i]\n",
    "        data2 = data[j]\n",
    "        data = np.delete(data, j, 0)  # 删除原数据\n",
    "        data = np.delete(data, i, 0)  # 删除原数据\n",
    "\n",
    "        # 最近两个点的中心点\n",
    "        b = np.atleast_2d(\n",
    "            [(data1[0] + data2[0]) / 2, (data1[1] + data2[1]) / 2]\n",
    "        )  # 计算两点新中心\n",
    "        data = np.concatenate((data, b), axis=0)  # 将新数据点添加到迭代过程\n",
    "        print(\"\\n最近距离:{} & {} = {}, 合并后中心:{}\\n\".format(data1, data2, min_distance, b))\n",
    "\n",
    "    return data\n",
    "\n",
    "# data[0] 去除点数据\n",
    "agglomerative_clustering(data[0])\n",
    "# 基于聚类结果构造数，即可快速得到不同 k 值的聚类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.cluster.AgglomerativeClustering(n_clusters=2, metric='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', pooling_func=<function mean>)\n",
    "\n",
    "# n_clusters: 表示最终要查找类别的数量，例如上面的 2 类。\n",
    "\n",
    "# metric: 有 euclidean（欧式距离）, l1（L1 范数）, l2（L2 范数）, manhattan（曼哈顿距离）等可选。\n",
    "\n",
    "# linkage: 连接方法：ward（单连接）, complete（全连接）, average（平均连接）可选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=2, metric=\"euclidean\", linkage=\"average\")\n",
    "model.fit_predict(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自顶向下层次聚类法：比自底向上复杂\n",
    "\n",
    "# 利用 k means 实现\n",
    "# 1.把数据集 D 归为单个类别 C 作为顶层。\n",
    "# 2.使用 K-Means 算法把 C 划分成 2 个子类别，构成子层；\n",
    "# 3.递归使用 K-Means 算法，分别对划分的子类，继续进行 2 类 划分子层直到每个点都是单独分类或特定条件结束\n",
    "\n",
    "# 利用平均距离进行分割\n",
    "\n",
    "# 1.把数据集 D 归为单个类别 C 作为顶层。\n",
    "# 2.从类别 C 中取出点 d，使得 d 满足到 C 中其他点的平均距离最远，构成类别 N。\n",
    "# 3.继续从类别 C 中取出点 d1， 使得 d1 满足到 C 中其他点的平均距离与到 N 中点的平均距离之间的差值最大，并将点放入 N。\n",
    "# 4.重复步骤 3，直到差值为负数。(直到点 d1 远离 N 类，接近 C 类)\n",
    "# 5.再从子类中重复步骤 2，3，4 直到全部点单独成类，即完成分割。\n",
    "# 自顶向下层次聚类法在实施过程中常常遇到一个问题，那就是如果两个样本在上一步聚类中被划分成不同的类别，那么即使这两个点距离非常近，后面也不会被放到一类中。\n",
    "# 在实际应用中，自顶向下层次聚类法没有自底而上的层次聚类法常用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIRCH 聚类算法\n",
    "# Balanced Iterative Reducing and Clustering using Hierarchies，直译过来就是「使用层次方法的平衡迭代规约和聚类」，该算法由时任 IBM 工程师 Tian Zhang 于 1996 年发明。\n",
    "# 优点：效率高，可用于大型数据集的快速聚类\n",
    "# 原理：基于训练样本建立了 CF 聚类特征树。CF 聚类特征树对应的输出就是若干个 CF 节点，每个节点里的样本点就是一个聚类的类别\n",
    "\n",
    "# BIRCH 算法在建立 CF 特征树时只存储原始数据的特征信息，并不需要存储原始数据信息，内存开销上更优，计算高效。\n",
    "# BIRCH 算法只需要遍历一遍原始数据，而 Agglomerative 算法在每次迭代都需要遍历一遍数据，再次突出 BIRCH 的高效性。\n",
    "# BIRCH 属于在线学习算法，并支持对流数据的聚类，开始聚类时并不需要知道所有的数据。\n",
    "\n",
    "# CF 聚类特征：对特征数据进行运算并且以元组的形式记录，定义类别（簇）的信息，并有效地对数据进行压缩\n",
    "# CF = (N,LS,SS)\n",
    "# N: 表示该 CF 中拥有的样本点的数量；  \n",
    "# LS: 表示该 CF 中拥有的样本点各特征维度的和向量；  所有点各维度间各自相加（结果是向量）\n",
    "# SS: 表示该 CF 中拥有的样本点各特征维度的平方和；  所有点维度值平方总和（结果是值）\n",
    "# CF 拥有可进行加法运算\n",
    "\n",
    "# CF Tree 聚类特征树\n",
    "# 枝平衡因子 β、叶平衡因子 λ 和空间阈值 t\n",
    "# 非叶节点包含多个子节点，不少于 β 个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_digits\n",
    "\n",
    "# 参数\n",
    "# images：8x8 矩阵，记录每张手写字符图像对应的像素灰度值\n",
    "\n",
    "# data：将 images 对应的 8x8 矩阵转换为行向量\n",
    "\n",
    "# target：记录 1797 张影像各自代表的数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "# 查看前 5 个字符\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 4))\n",
    "for i, image in enumerate(digits.images[:5]):\n",
    "    axes[i].imshow(image, cmap=plt.cm.gray_r)\n",
    "\n",
    "    digits.images[0]\n",
    "    # 升维转化：对矩阵进行扁平化处理,可以转化为高维向量，在聚类时直接计算距离\n",
    "    # - 8 x 8 -> 1 x 64\n",
    "    # - 问题：难以在图像上绘制出来\n",
    "    # 降维转化：PCA 主成分分析\n",
    "    # - 1 x 64 -> 1 x 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 主成分分析 Principal Components Analysis\n",
    "# 降低数据的维数，通过保留数据集中的主要成分来简化数据集\n",
    "# 数学原理：通过对协方差矩阵进行特征分解，从而得出主成分（特征向量）与对应的权值（特征值）。然后剔除那些较小特征值（较小权值）对应的特征，从而达到降低数据维数的目的。\n",
    "\n",
    "# 作用\n",
    "# 1.方便将数据用于低维空间可视化。聚类过程中的可视化是很有必要的。\n",
    "# 2.高维度数据集往往就意味着计算资源的大量消耗。通过对数据进行降维，我们就能在不较大影响结果的同时，减少模型学习时间。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver='auto')\n",
    "\n",
    "# n_components= 表示需要保留主成分（特征）的数量。\n",
    "\n",
    "# copy= 表示针对原始数据降维还是针对原始数据副本降维。当参数为 False 时，降维后的原始数据会发生改变，这里默认为 True。\n",
    "\n",
    "# whiten= 白化表示将特征之间的相关性降低，并使得每个特征具有相同的方差。\n",
    "\n",
    "# svd_solver= 表示奇异值分解 SVD 的方法。有 4 参数，分别是：auto, full, arpack, randomized。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 将数据降为 2 维\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(digits.data)\n",
    "pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birch 聚类\n",
    "\n",
    "# sklearn.cluster.Birch(threshold=0.5, branching_factor=50, n_clusters=3, compute_labels=True, copy=True)\n",
    "\n",
    "# threshold: 每个 CF 的空间阈值 \n",
    "# 。参数值越小，则 CF 特征树的规模会越大，学习时花费的时间和内存会越多。默认值是 0.5，但如果样本的方差较大，则一般需要增大这个默认值。\n",
    "\n",
    "# branching_factor: CF 树中所有节点的最大 CF 数。该参数默认为 50，如果样本量非常大，一般需要增大这个默认值。\n",
    "\n",
    "# n_clusters: 虽然层次聚类无需预先设定类别数量，但可以设定期望查询的类别数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "birch = Birch(n_clusters=10)\n",
    "cluster_pca = birch.fit_predict(pca_data)\n",
    "cluster_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=cluster_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制聚类边界\n",
    "\n",
    "# 计算聚类过程中的决策边界\n",
    "x_min, x_max = pca_data[:, 0].min() - 1, pca_data[:, 0].max() + 1\n",
    "y_min, y_max = pca_data[:, 1].min() - 1, pca_data[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.4), np.arange(y_min, y_max, 0.4))\n",
    "temp_cluster = birch.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# 将决策边界绘制出来\n",
    "temp_cluster = temp_cluster.reshape(xx.shape)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, temp_cluster, cmap=plt.cm.bwr, alpha=0.3)\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=cluster_pca, s=15)\n",
    "\n",
    "# 图像参数设置\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接用原始数据进行聚类\n",
    "cluster_ori = birch.fit_predict(digits.data)\n",
    "cluster_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_data[:, 0], pca_data[:, 1], c=cluster_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 使用场景\n",
    "# 一般情况下，我们不会拿到数据就进行 PCA 处理，只有当算法不尽如人意、训练时间太长、需要可视化等情形才考虑使用 PCA。其主要原因是，PCA 被看作是对数据的有损压缩，会造成数据集原始特征丢失。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
