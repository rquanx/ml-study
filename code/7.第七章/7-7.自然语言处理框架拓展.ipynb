{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1eb9c-b5db-4965-9f5f-e8676c8cb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0600ae-d3aa-4fc9-a74c-d5d190273688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91658\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt') # 下载英文分词所需拓展包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3369c47-0c9d-4633-8ba9-7997760cd6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'English', ']', 'is', 'a', 'West', 'Germanic', 'language', 'that', 'was', 'first', 'spoken', 'in', 'early', 'medieval', 'England', 'and', 'eventually', 'became', 'a', 'global', 'lingua', 'franca', '.', 'It', 'is', 'named', 'after', 'the', '<', 'Angles', '>', ',', 'one', 'of', 'the', 'Germanic', 'tribes', 'that', 'migrated', 'to', 'the', 'area', 'of', 'Great', 'Britain', 'that', 'later', 'took', 'their', 'name', ',', 'as', 'England', '.']\n"
     ]
    }
   ],
   "source": [
    "# 使用 nltk.tokenize.word_tokenize 完成英文文本分词\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"\"\"\n",
    "[English] is a West Germanic language that was first spoken in early\n",
    "medieval England and eventually became a global lingua franca.\n",
    "It is named after the <Angles>, one of the Germanic tribes that\n",
    "migrated to the area of Great Britain that later took their name,\n",
    "as England.\n",
    "\"\"\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e16b8c9-0570-4e15-926c-cb9a9ebca592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n[English] is a West Germanic language that was first spoken in early\\nmedieval England and eventually became a global lingua franca.',\n",
       " 'It is named after the <Angles>, one of the Germanic tribes that\\nmigrated to the area of Great Britain that later took their name,\\nas England.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本断句\n",
    "from nltk import sent_tokenize\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5dea930-3ccc-4932-bf50-fd4ee8b8ad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'English',\n",
       " ']',\n",
       " 'is',\n",
       " 'a',\n",
       " 'West',\n",
       " 'Germanic',\n",
       " 'language',\n",
       " 'that',\n",
       " 'was',\n",
       " 'first',\n",
       " 'spoken',\n",
       " 'in',\n",
       " 'early',\n",
       " 'medieval',\n",
       " 'England',\n",
       " 'and',\n",
       " 'eventually',\n",
       " 'became',\n",
       " 'a',\n",
       " 'global',\n",
       " 'lingua',\n",
       " 'franca',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " '<',\n",
       " 'Angles',\n",
       " '>',\n",
       " ',',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Germanic',\n",
       " 'tribes',\n",
       " 'that',\n",
       " 'migrated',\n",
       " 'to',\n",
       " 'the',\n",
       " 'area',\n",
       " 'of',\n",
       " 'Great',\n",
       " 'Britain',\n",
       " 'that',\n",
       " 'later',\n",
       " 'took',\n",
       " 'their',\n",
       " 'name',\n",
       " ',',\n",
       " 'as',\n",
       " 'England',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本过滤。例如去除文本中的标点符号，通过遍历分词结果，仅保留英文内容\n",
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e944738c-f311-40f5-928d-b1f44abd5539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'is', 'a', 'West', 'Germanic', 'language', 'that', 'was', 'first', 'spoken', 'in', 'early', 'medieval', 'England', 'and', 'eventually', 'became', 'a', 'global', 'lingua', 'franca', 'It', 'is', 'named', 'after', 'the', 'Angles', 'one', 'of', 'the', 'Germanic', 'tribes', 'that', 'migrated', 'to', 'the', 'area', 'of', 'Great', 'Britain', 'that', 'later', 'took', 'their', 'name', 'as', 'England']\n"
     ]
    }
   ],
   "source": [
    "# 仅保留 alphabetic\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee917aa-85c2-4ab5-b24d-61cd9710a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91658\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# 去除英文停用词\n",
    "# 停用词大拳：Dutch, German, Italian, Portuguese, Swedish, Arabic, English, Greek, Kazakh, Romanian, Turkish Azerbaijani, Finnish, Hungarian, Nepali, Russian, Danish, French, Indonesian, Norwegian, Spanish 等语言的停用词\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords') # 安装停用词拓展包\n",
    "stop_words = stopwords.words(\"english\") # 加载英文停用词\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708d443c-be46-47e6-a9fe-d51f927d9bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'West', 'Germanic', 'language', 'first', 'spoken', 'early', 'medieval', 'England', 'eventually', 'became', 'global', 'lingua', 'franca', 'It', 'named', 'Angles', 'one', 'Germanic', 'tribes', 'migrated', 'area', 'Great', 'Britain', 'later', 'took', 'name', 'England']\n"
     ]
    }
   ],
   "source": [
    "words_ = [w for w in words if not w in stop_words]\n",
    "print(words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240941c9-dc5b-47fd-8e5c-e8ea6098907d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 3, 'the': 3, 'is': 2, 'a': 2, 'Germanic': 2, 'England': 2, '.': 2, ',': 2, 'of': 2, '[': 1, ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.FreqDist 按降序返回词频字典\n",
    "from nltk import FreqDist\n",
    "FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2852f3-f30a-43ec-af3b-3e17adcb1666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'english', ']', 'is', 'a', 'west', 'german', 'languag', 'that', 'wa', 'first', 'spoken', 'in', 'earli', 'mediev', 'england', 'and', 'eventu', 'becam', 'a', 'global', 'lingua', 'franca', '.', 'it', 'is', 'name', 'after', 'the', '<', 'angl', '>', ',', 'one', 'of', 'the', 'german', 'tribe', 'that', 'migrat', 'to', 'the', 'area', 'of', 'great', 'britain', 'that', 'later', 'took', 'their', 'name', ',', 'as', 'england', '.']\n"
     ]
    }
   ],
   "source": [
    "# PorterStemmer 实现对句子中词干的提取。词干提取是语言形态学中的概念，词干提取的目的是去除词缀得到词根，例如 Germanic 的词干为 german\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597ef15-67dc-4690-a21c-946c5a8b715d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b467668-59ce-43e0-8557-2d6d0bbf1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c9d621-c9c5-4361-a4d6-4c963de2df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence[55]: \" [English] is a West Germanic language that was first spoken in early medieval England and eventually became a global lingua franca. It is named after the <Angles>, one of the Germanic tribes that migrated to the area of Great Britain that later took their name, as England.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "text = \"\"\"\n",
    "[English] is a West Germanic language that was first spoken in early\n",
    "medieval England and eventually became a global lingua franca.\n",
    "It is named after the <Angles>, one of the Germanic tribes that\n",
    "migrated to the area of Great Britain that later took their name,\n",
    "as England.\n",
    "\"\"\"\n",
    "\n",
    "# Flair 会自动按照空格识别每一个 Sentence 包含的 Tokens 数量\n",
    "sentence = Sentence(text)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e51cfd-e6c4-40e4-8207-f9bfe36dd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token[0]: \"[\"\n",
      "Token[1]: \"English\"\n",
      "Token[2]: \"]\"\n",
      "Token[3]: \"is\"\n",
      "Token[4]: \"a\"\n",
      "Token[5]: \"West\"\n",
      "Token[6]: \"Germanic\"\n",
      "Token[7]: \"language\"\n",
      "Token[8]: \"that\"\n",
      "Token[9]: \"was\"\n",
      "Token[10]: \"first\"\n",
      "Token[11]: \"spoken\"\n",
      "Token[12]: \"in\"\n",
      "Token[13]: \"early\"\n",
      "Token[14]: \"medieval\"\n",
      "Token[15]: \"England\"\n",
      "Token[16]: \"and\"\n",
      "Token[17]: \"eventually\"\n",
      "Token[18]: \"became\"\n",
      "Token[19]: \"a\"\n",
      "Token[20]: \"global\"\n",
      "Token[21]: \"lingua\"\n",
      "Token[22]: \"franca\"\n",
      "Token[23]: \".\"\n",
      "Token[24]: \"It\"\n",
      "Token[25]: \"is\"\n",
      "Token[26]: \"named\"\n",
      "Token[27]: \"after\"\n",
      "Token[28]: \"the\"\n",
      "Token[29]: \"<\"\n",
      "Token[30]: \"Angles\"\n",
      "Token[31]: \">\"\n",
      "Token[32]: \",\"\n",
      "Token[33]: \"one\"\n",
      "Token[34]: \"of\"\n",
      "Token[35]: \"the\"\n",
      "Token[36]: \"Germanic\"\n",
      "Token[37]: \"tribes\"\n",
      "Token[38]: \"that\"\n",
      "Token[39]: \"migrated\"\n",
      "Token[40]: \"to\"\n",
      "Token[41]: \"the\"\n",
      "Token[42]: \"area\"\n",
      "Token[43]: \"of\"\n",
      "Token[44]: \"Great\"\n",
      "Token[45]: \"Britain\"\n",
      "Token[46]: \"that\"\n",
      "Token[47]: \"later\"\n",
      "Token[48]: \"took\"\n",
      "Token[49]: \"their\"\n",
      "Token[50]: \"name\"\n",
      "Token[51]: \",\"\n",
      "Token[52]: \"as\"\n",
      "Token[53]: \"England\"\n",
      "Token[54]: \".\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 指定 use_tokenizer=True，就会自动调用 segtok 完成英文分词\n",
    "sentence = Sentence(text, use_tokenizer=True)\n",
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01826b98-3c91-43af-be5e-3c1ad1de519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-15 02:02:08,129 https://flair.informatik.hu-berlin.de/resources/embeddings/token/zh-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to C:\\Users\\91658\\AppData\\Local\\Temp\\tmp613zk5kr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▉                                   | 29.0M/381M [00:21<03:32, 1.74MB/s]"
     ]
    }
   ],
   "source": [
    "# 对 Sentence 进行 Word Embedding 词嵌入\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "# 初始化 embedding\n",
    "embedding = WordEmbeddings('zh') # 自行实现时请替换为 `zh`\n",
    "# 创建 sentence，中文需传入分词后用空格间隔的语句，才能被 Flair 识别出 tokens\n",
    "sentence = Sentence(\"机器 学习 是 一个 好 工具\")\n",
    "# 词嵌入\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e7c50-d38b-4105-a77e-7132c6e75cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding) # 输出词嵌入后向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a9504-eba0-41b9-a29b-98131a198735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "sentence = Sentence(\"人工智能\")\n",
    "embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cde33-f699-48a8-a3ab-910f77f1a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText 提供的中文词嵌入向量长度为 300\n",
    "from flair.embeddings import BertEmbeddings\n",
    "embedding = BertEmbeddings('bert-base-chinese')\n",
    "\n",
    "# wget -nc \"https://cdn.aibydoing.com/aibydoing/files/wsdm_mini.csv\" # 假新闻数据\n",
    "\n",
    "# wget -nc \"https://cdn.aibydoing.com/aibydoing/files/stopwords.txt\" # 停用词词典"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
